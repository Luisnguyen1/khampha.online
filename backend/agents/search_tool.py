"""
Web search tool using DuckDuckGo
No API key required
"""
from typing import List, Dict, Optional
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class SearchTool:
    """Web search using DuckDuckGo"""
    
    def __init__(self, max_results: int = 5, timeout: int = 10):
        self.max_results = max_results
        self.timeout = timeout
    
    def search(self, query: str, max_results: Optional[int] = None) -> List[Dict[str, str]]:
        """
        Search the web using DuckDuckGo
        
        Args:
            query: Search query
            max_results: Maximum number of results to return
            
        Returns:
            List of search results with title, snippet, url
        """
        logger.info(f"üîç Starting search for: '{query}'")
        
        try:
            from ddgs import DDGS
            logger.info("‚úÖ DuckDuckGo library imported successfully")
            
            results = []
            max_res = max_results or self.max_results
            logger.info(f"üìä Max results requested: {max_res}")
            
            try:
                # Fixed: Remove proxies parameter and use simpler initialization
                ddgs = DDGS(timeout=self.timeout)
                logger.info("üåê DDGS instance created, performing search...")
                
                # Use the text search method - use 'query' as first positional argument
                search_results = ddgs.text(
                    query,  # First positional argument
                    region='vn-vi',  # Vietnam region
                    safesearch='moderate',
                    timelimit='y',  # Last year
                    max_results=max_res
                )
                
                logger.info("üì• Search results received, processing...")
                
                # Handle both generator and list returns
                result_list = list(search_results) if search_results else []
                
                for i, r in enumerate(result_list):
                    results.append({
                        'title': r.get('title', ''),
                        'snippet': r.get('body', ''),
                        'url': r.get('href', ''),
                        'source': 'duckduckgo'
                    })
                    logger.debug(f"  Result {i+1}: {r.get('title', 'No title')[:50]}...")
                
                logger.info(f"‚úÖ Search completed: {query} - {len(results)} results")
                return results
                
            except Exception as ddgs_error:
                logger.error(f"‚ùå DuckDuckGo search failed: {type(ddgs_error).__name__}: {str(ddgs_error)}")
                logger.warning("‚ö†Ô∏è Falling back to mock results")
                return self._mock_search(query, max_results)
            
        except ImportError as import_error:
            logger.warning(f"‚ö†Ô∏è duckduckgo-search not installed: {str(import_error)}")
            logger.info("üì¶ Returning mock results")
            return self._mock_search(query, max_results)
        
        except Exception as e:
            logger.error(f"‚ùå Unexpected search error: {type(e).__name__}: {str(e)}")
            logger.warning("‚ö†Ô∏è Returning mock results as fallback")
            return self._mock_search(query, max_results)
    
    def _mock_search(self, query: str, max_results: Optional[int] = None) -> List[Dict[str, str]]:
        """
        Mock search results for development/testing
        Returns realistic-looking travel information
        """
        logger.info(f"üé≠ Using mock search for query: '{query}'")
        max_res = max_results or self.max_results
        
        # Extract location from query
        location = query.split()[0] if query else "Vi·ªát Nam"
        logger.info(f"üìç Extracted location: {location}")
        
        mock_results = [
            {
                'title': f'Du l·ªãch {location} - C·∫©m nang t·ª´ A-Z',
                'snippet': f'Kh√°m ph√° {location} v·ªõi l·ªãch tr√¨nh chi ti·∫øt, ƒë·ªãa ƒëi·ªÉm tham quan n·ªïi ti·∫øng, ·∫©m th·ª±c ƒë·∫∑c s·∫£n v√† kinh nghi·ªám du l·ªãch t·ª± t√∫c. C·∫≠p nh·∫≠t 2025.',
                'url': f'https://example.com/{location.lower()}-guide',
                'source': 'mock'
            },
            {
                'title': f'Top 10 ƒëi·ªÉm ƒë·∫øn t·∫°i {location} kh√¥ng th·ªÉ b·ªè qua',
                'snippet': f'Danh s√°ch c√°c ƒë·ªãa ƒëi·ªÉm du l·ªãch ƒë·∫πp nh·∫•t t·∫°i {location}: b√£i bi·ªÉn, n√∫i non, di t√≠ch l·ªãch s·ª≠, l√†ng ngh·ªÅ truy·ªÅn th·ªëng...',
                'url': f'https://example.com/{location.lower()}-top-10',
                'source': 'mock'
            },
            {
                'title': f'Chi ph√≠ du l·ªãch {location} 2025: ƒÇn, ·ªü, ƒëi l·∫°i',
                'snippet': f'∆Ø·ªõc t√≠nh chi ph√≠ cho chuy·∫øn du l·ªãch {location}: v√© m√°y bay, kh√°ch s·∫°n, ƒÉn u·ªëng, v√© tham quan. C·∫≠p nh·∫≠t b·∫£ng gi√° m·ªõi nh·∫•t.',
                'url': f'https://example.com/{location.lower()}-budget',
                'source': 'mock'
            },
            {
                'title': f'Review {location}: Kinh nghi·ªám th·ª±c t·∫ø',
                'snippet': f'Chia s·∫ª kinh nghi·ªám du l·ªãch {location} c·ªßa m√¨nh: th·ªùi ƒëi·ªÉm ƒë·∫πp nh·∫•t, c√°ch di chuy·ªÉn, n√™n ·ªü ƒë√¢u, ƒÉn g√¨ ngon...',
                'url': f'https://example.com/{location.lower()}-review',
                'source': 'mock'
            },
            {
                'title': f'L·ªãch tr√¨nh {location} 3 ng√†y 2 ƒë√™m chi ti·∫øt',
                'snippet': f'G·ª£i √Ω l·ªãch tr√¨nh {location} cho ng∆∞·ªùi ƒëi l·∫ßn ƒë·∫ßu: ng√†y 1 kh√°m ph√° trung t√¢m, ng√†y 2 tham quan ngo·∫°i th√†nh, ng√†y 3 mua s·∫Øm v√† v·ªÅ.',
                'url': f'https://example.com/{location.lower()}-itinerary',
                'source': 'mock'
            }
        ]
        
        return mock_results[:max_res]
    
    def search_multiple(self, queries: List[str], max_per_query: int = 3) -> Dict[str, List[Dict]]:
        """
        Search multiple queries and return grouped results
        
        Args:
            queries: List of search queries
            max_per_query: Max results per query
            
        Returns:
            Dictionary mapping query to results
        """
        results = {}
        
        for query in queries:
            results[query] = self.search(query, max_results=max_per_query)
        
        return results
    
    def format_results_for_llm(self, results: List[Dict[str, str]]) -> str:
        """
        Format search results for LLM consumption
        
        Args:
            results: List of search results
            
        Returns:
            Formatted string with numbered results
        """
        if not results:
            return "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ t√¨m ki·∫øm."
        
        formatted = "TH√îNG TIN T√åM KI·∫æM:\n\n"
        
        for i, result in enumerate(results, 1):
            formatted += f"{i}. **{result['title']}**\n"
            formatted += f"   {result['snippet']}\n"
            formatted += f"   üîó {result['url']}\n\n"
        
        return formatted
    
    def extract_sources_for_storage(self, results: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        Extract source information for storage in database
        
        Args:
            results: List of search results
            
        Returns:
            List of dicts with title, url, snippet for each source
        """
        sources = []
        for result in results:
            sources.append({
                'title': result.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ'),
                'url': result.get('url', ''),
                'snippet': result.get('snippet', '')[:200]  # Limit snippet length
            })
        return sources
    
    def extract_travel_info(self, results: List[Dict[str, str]]) -> Dict[str, any]:
        """
        Extract structured travel information from search results
        
        Args:
            results: List of search results
            
        Returns:
            Dictionary with structured travel info
        """
        # Combine all snippets
        all_text = " ".join([r['snippet'] for r in results])
        
        # Simple keyword extraction (can be improved with NLP)
        info = {
            'has_cost_info': any(word in all_text.lower() for word in ['gi√°', 'chi ph√≠', 'vnƒë', 'ƒë·ªìng']),
            'has_activities': any(word in all_text.lower() for word in ['tham quan', 'ho·∫°t ƒë·ªông', 'ƒëi·ªÉm ƒë·∫øn']),
            'has_food': any(word in all_text.lower() for word in ['·∫©m th·ª±c', 'm√≥n ƒÉn', 'nh√† h√†ng']),
            'has_accommodation': any(word in all_text.lower() for word in ['kh√°ch s·∫°n', 'homestay', 'l∆∞u tr√∫']),
            'total_results': len(results),
            'sources': [r['url'] for r in results]
        }
        
        return info


# Example usage
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    
    search = SearchTool(max_results=3)
    
    # Test single search
    print("Testing single search...")
    results = search.search("du l·ªãch ƒê√† L·∫°t")
    print(f"Found {len(results)} results")
    
    # Test formatted output
    print("\nFormatted for LLM:")
    print(search.format_results_for_llm(results))
    
    # Test info extraction
    print("\nExtracted info:")
    info = search.extract_travel_info(results)
    print(info)
